{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab3ff6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "def _to_set(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return set()\n",
    "    if isinstance(x, (list, tuple)):\n",
    "        return set(x)\n",
    "    if isinstance(x, str):\n",
    "        try:\n",
    "            v = ast.literal_eval(x)\n",
    "            if isinstance(v, (list, tuple)):\n",
    "                return set(v)\n",
    "        except Exception:\n",
    "            pass\n",
    "        return set(x.split(\",\"))\n",
    "    return set()\n",
    "\n",
    "\n",
    "def build_agent_features(train: pd.DataFrame, test: pd.DataFrame) -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for agent, test_g in test.groupby(\"agent\", sort=False):\n",
    "        train_g = train[train[\"agent\"] == agent]\n",
    "        if train_g.empty:\n",
    "            continue\n",
    "\n",
    "        max_feats = {\n",
    "            \"f_duration\": 0.0,\n",
    "            \"f_dist\": 0.0,\n",
    "            \"f_speed_1\": 0.0,\n",
    "            \"f_speed_2\": 0.0,\n",
    "            \"f_trans_jaccard\": 0.0,\n",
    "        }\n",
    "\n",
    "        for _, tr in test_g.iterrows():\n",
    "            # same dominant_poi first\n",
    "            cand = train_g[train_g[\"dominant_poi\"] == tr[\"dominant_poi\"]]\n",
    "            if cand.empty:\n",
    "                cand = train_g  # fallback\n",
    "\n",
    "            best = {\n",
    "                \"f_duration\": np.inf,\n",
    "                \"f_dist\": np.inf,\n",
    "                \"f_speed_1\": np.inf,\n",
    "                \"f_speed_2\": np.inf,\n",
    "                \"f_trans_jaccard\": np.inf,\n",
    "            }\n",
    "\n",
    "            t_set = _to_set(tr[\"transformation\"])\n",
    "\n",
    "            for _, rr in cand.iterrows():\n",
    "                r_set = _to_set(rr[\"transformation\"])\n",
    "\n",
    "                inter = len(t_set & r_set)\n",
    "                union = len(t_set | r_set)\n",
    "                jac = 1.0 - (inter / union if union else 0.0)\n",
    "\n",
    "                best[\"f_duration\"] = min(best[\"f_duration\"], abs(tr[\"duration_min\"] - rr[\"duration_min\"]))\n",
    "                best[\"f_dist\"] = min(best[\"f_dist\"], abs(tr[\"max_distance_from_home\"] - rr[\"max_distance_from_home\"]))\n",
    "                best[\"f_speed_1\"] = min(best[\"f_speed_1\"], abs(tr[\"avg_speed_first_half\"] - rr[\"avg_speed_first_half\"]))\n",
    "                best[\"f_speed_2\"] = min(best[\"f_speed_2\"], abs(tr[\"avg_speed_second_half\"] - rr[\"avg_speed_second_half\"]))\n",
    "                best[\"f_trans_jaccard\"] = min(best[\"f_trans_jaccard\"], jac)\n",
    "\n",
    "            for k in max_feats:\n",
    "                max_feats[k] = max(max_feats[k], best[k])\n",
    "\n",
    "        rows.append({\n",
    "            \"agent\": agent,\n",
    "            **max_feats,\n",
    "            \"label\": int(test_g[\"label\"].max()),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1de9374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def fit_logistic_weights(agent_df: pd.DataFrame):\n",
    "    feature_cols = [\n",
    "        \"f_duration\",\n",
    "        \"f_dist\",\n",
    "        \"f_speed_1\",\n",
    "        \"f_speed_2\",\n",
    "        \"f_trans_jaccard\",\n",
    "    ]\n",
    "\n",
    "    X = agent_df[feature_cols].to_numpy()\n",
    "    y = agent_df[\"label\"].to_numpy()\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            penalty=\"l1\",\n",
    "            solver=\"liblinear\",\n",
    "            class_weight=\"balanced\",\n",
    "            max_iter=2000,\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "    weights = pipe.named_steps[\"clf\"].coef_[0]\n",
    "    intercept = pipe.named_steps[\"clf\"].intercept_[0]\n",
    "\n",
    "    return dict(zip(feature_cols, weights)), intercept, pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc84c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/Users/chanuka/Desktop/codespaces/liad/processed/trial5/sim1/10k/ore/or_train.csv')\n",
    "test = pd.read_csv('/Users/chanuka/Desktop/codespaces/liad/processed/trial5/sim1/10k/ore/or_test.csv')\n",
    "\n",
    "gt = pd.read_csv('/Users/chanuka/Desktop/codespaces/liad/processed/trial5/sim1/gt/anomalous_temporal.csv')\n",
    "test['started_at']  = pd.to_datetime(test['started_at'])\n",
    "test['finished_at'] = pd.to_datetime(test['finished_at'])\n",
    "\n",
    "train['started_at']  = pd.to_datetime(train['started_at'])\n",
    "train['finished_at'] = pd.to_datetime(train['finished_at'])\n",
    "\n",
    "gt['started_at'] = pd.to_datetime(gt['started_at']) \n",
    "gt['started_at'] = gt['started_at'].dt.tz_convert('Asia/Tokyo')\n",
    "gt['finished_at'] = pd.to_datetime(gt['finished_at']) \n",
    "gt['finished_at'] = gt['finished_at'].dt.tz_convert('Asia/Tokyo')\n",
    "\n",
    "# # adding ground truth\n",
    "train['label'] = 0\n",
    "test['label'] = 0\n",
    "\n",
    "for agent, gt_agent in gt.groupby('agent'):\n",
    "    agent_mask = test['agent'] == agent\n",
    "\n",
    "    if not agent_mask.any():\n",
    "        continue\n",
    "\n",
    "    for _, row in gt_agent.iterrows():\n",
    "        anomaly_start_time = row['started_at']\n",
    "        anomaly_end_time   = row['finished_at']\n",
    "\n",
    "        overlap_mask = (\n",
    "            agent_mask &\n",
    "            (test['started_at'] < anomaly_end_time) &\n",
    "            (test['finished_at'] > anomaly_start_time)\n",
    "        )\n",
    "\n",
    "        test.loc[overlap_mask, 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51628ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned weights:\n",
      "f_duration          : +0.9954\n",
      "f_dist              : +1.0792\n",
      "f_speed_1           : +0.0466\n",
      "f_speed_2           : +0.3712\n",
      "f_trans_jaccard     : -0.3132\n",
      "Intercept: -0.6771675175820481\n"
     ]
    }
   ],
   "source": [
    "agent_features = build_agent_features(train, test)\n",
    "\n",
    "weights, intercept, model = fit_logistic_weights(agent_features)\n",
    "\n",
    "print(\"Learned weights:\")\n",
    "for k, v in weights.items():\n",
    "    print(f\"{k:20s}: {v:+.4f}\")\n",
    "\n",
    "print(\"Intercept:\", intercept)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
